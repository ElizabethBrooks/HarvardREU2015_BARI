{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes Text Classification ##\n",
    "\n",
    "Tha following program applies the Naive Bayes classifier provided by NLTK to input data files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Author: Elizabeth Brooks\n",
    "# Date Modified: 07/06/2015\n",
    "\n",
    "# PreProcessor Directives\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "from scipy.misc import imread\n",
    "import re\n",
    "# Import necessary NB classifier func\n",
    "from nltk.classify import apply_features\n",
    "import random\n",
    "# Add parent directory to path for twc imports\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.realpath('../'))\n",
    "import twittercriteria as twc\n",
    "\n",
    "# Global field declarations\n",
    "twc.loadCriteria()\n",
    "twc.clearCriteria()\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# Function to clean up tweet strings \n",
    "# by manually removing irrelevant data (not words)\n",
    "def cleanUpTweet(tweet_text):\n",
    "    # Irrelevant characters\n",
    "    twitterMarkup = ['&amp;', 'http://t.co/']\n",
    "    temp = tweet_text.lower()\n",
    "    # Use regex to create a regular expression \n",
    "    # for removing undesired characters\n",
    "    temp = re.sub('|'.join(twitterMarkup), r\"\", temp)\n",
    "    return temp\n",
    "# End cleanUpTweet\n",
    "\n",
    "# Function to search for tweets based on pre-determined key words\n",
    "def tweetHasAKeyword(tweet_text):\n",
    "    return keyword.search(tweet_text) is not None\n",
    "# End tweetHasAKeyword"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above function removes irrelevant characters from the tweet strings contained in the Twitter data csv files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function for organizing data for labeling\n",
    "def orgData(txt_data):\n",
    "    # Set the output file path\n",
    "    relevantPath = current_dir + '/RelevantTweets.txt'\n",
    "    irrelevantPath = current_dir + '/IrrelevantTweets.txt'\n",
    "    # Create object for writting to a text file\n",
    "    relevantTxtFile = open(relevantPath, \"w\")\n",
    "    irrelevantTxtFile = open(irrelevantPath, \"w\")\n",
    "    # Determie the label to assign a tweet based on keyword\n",
    "    if tweetHasAKeyword(tweetText):\n",
    "        relevantTxtFile.write(tweetText)\n",
    "    else:\n",
    "        irrelevantTxtFile.write(tweetText)\n",
    "    # End else\n",
    "    # Close the files\n",
    "    relevantTxtFile.close()\n",
    "    irrelevantTxtFile.close()\n",
    "# End orgData\n",
    "\n",
    "# Function to extract relevant features\n",
    "def extractFeatures(txt_data):\n",
    "    # Create object for writting to a text file\n",
    "    relevantTxtFile = open(relevantPath, \"w\")\n",
    "    irrelevantTxtFile = open(irrelevantPath, \"w\")\n",
    "    # Assign labels to tweets\n",
    "    labeledTweets = ([(word, 'relevant') for word in relevantTxtFile.read().split()] +\n",
    "        [(word, 'irrelevant') for word in irrelevantTxtFile.read().split()])\n",
    "    # Close the files\n",
    "    relevantTxtFile.close()\n",
    "    irrelevantTxtFile.close()\n",
    "    \n",
    "    # Extract keywords\n",
    "# End trainTxtData\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above functions are used to first organize the data into text file by relevance accoring to the pre determined list of keyword, then a second function extracts these tweets features to be used to build classes and identify tweets for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function for training the classifier\n",
    "def trainData():\n",
    "    # Determine the feature sets\n",
    "    featureSets = [(extractFeatures(tweetTerm), relevance) for (tweetTerm, relevance) in labeledTweets]\n",
    "    # Randomize the data\n",
    "    random.shuffle(labeledNames)\n",
    "\n",
    "    # Establish the training and dev data sets\n",
    "    trainSet, devSet = featureSets[500:], featuresSets[:500] #before and after 500\n",
    "\n",
    "    # Train the Naive Bayes (NB) classifier\n",
    "    classifierNB = nltk.NaiveBayesClassifier.train(trainSet)\n",
    "# End trainData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The main method\n",
    "def main():\n",
    "    # Set the output file path\n",
    "    txtFilePath = current_dir + '/OutputTweets.txt'\n",
    "    # Create object for writting to a text file\n",
    "    tweetTxtFile = open(txtFilePath, \"w\")\n",
    "    \n",
    "    # Request user input of the file name of the data to be processed\n",
    "    inputFile = raw_input(\"Enter csv file name...\\nEx: cleaned_geo_tweets_Apr_12_to_22\")\n",
    "\n",
    "    # Iterate through the Twitter data csv files by tweet text\n",
    "    with open(current_dir + '/../' + inputFile + '.csv') as csvfile:  \n",
    "        tweetIt = csv.DictReader(csvfile)\n",
    "        # Retrieve the strings of tweets\n",
    "        for twitterData in tweetIt:\n",
    "            # Convert tweets to lower case to pool words of the same spelling\n",
    "            # Send the tweet text to the function for removing unncessary characters\n",
    "            tweetText = cleanUpTweet(twitterData['tweet_text'])\n",
    "            # Write the selected Twitter data, tweets, to the txt file\n",
    "            tweetTxtFile.write(tweetText)\n",
    "    # Close the file obj\n",
    "    tweetTxtFile.close()\n",
    "    # Organize the data by relevance according to keyword dictionary\n",
    "    orgData(tweetTxtFile)\n",
    "    # Use the defined function to extract relevant features (terms)\n",
    "    extractFeatures(tweetTxtFile)\n",
    "# End main\n",
    "\n",
    "# Run the script via the main method\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "    \n",
    "# End script"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
