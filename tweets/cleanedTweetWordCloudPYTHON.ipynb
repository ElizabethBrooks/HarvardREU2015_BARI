{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A program for generating tweet based word clouds. Specifically in regards to the \"cleaned\", geo-tagged Twitter data from April 12 to 22 of 2013.\n",
    "\n",
    "The program may be easily altered to create any number of word clouds given an input txt file. A csv file may be used as well, the relavent information from which is parsed and saved into a txt file for use by the word cloud function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Author: Elizabeth Brooks\n",
    "# Date Modified: 06/24/2015\n",
    "\n",
    "# PreProcessor Directives\n",
    "import csv\n",
    "from os import path\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "# The main method\n",
    "def main():\n",
    "    # Create object for writting to a text file\n",
    "    tweetFile = open(\"OutputTweets.txt\", \"w\")\n",
    "\n",
    "    # Iterate through the \"cleaned\" Twitter data by tweet\n",
    "    with open('cleaned_geo_tweets_Apr_12_to_22.csv') as csvfile:  \n",
    "      tweetIt = csv.DictReader(csvfile)\n",
    "      # Retrieve the strings of tweets\n",
    "      for twitterData in tweetIt:\n",
    "        # Convert tweets to lower case to pool words of the same spelling\n",
    "        twitterData['tweet_text'] = twitterData['tweet_text'].lower()\n",
    "        # Write the selected Twitter data, tweets, to the txt file\n",
    "        tweetFile.write(twitterData['tweet_text'])\n",
    "\n",
    "    # Close the file obj\n",
    "    tweetFile.close()\n",
    "    \n",
    "    # Use the defined function to create the tweet word cloud\n",
    "    tweetWordCloud()\n",
    "# End main "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code creates a file object and opens a txt file to store all the strings of tweets contained in the Twitter data from the \"cleaned\" tweets csv file. The tweet strings are then retrieved from the csv file by iterating through the tweet hashes made by the DictReader. Finally, these strings are converted to lower case. This is because we are interested in looking at the occurances of a given spelling of a word, regardless of case; stemming may be considered in the future to combine the frequencies of all conjugate forms of a words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function for generating a word cloud\n",
    "def tweetWordCloud():\n",
    "    db = path.dirname(_file_)\n",
    "    # Read in the txt file set by the main method\n",
    "    text = open(path.join(db, 'OutputTweets.txt')).read()\n",
    "    # Generate the word cloud\n",
    "    wordCloud = WordCloud().generate(text)\n",
    "    # Open a plot of the generated word cloud\n",
    "    plt.imshow(wordcloud)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "# End tweetWordCloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above function generates a word cloud based on words in the txt file created in the main method.\n",
    "\n",
    "For more info: https://github.com/amueller/word_cloud"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
