{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keyword Tweet Word Cloud (Windows OS) ##\n",
    "\n",
    "A program for generating tweet based word clouds. Specifically in regards to the _cleaned_, geo-tagged Twitter data from April 12 to 22 of 2013.\n",
    "\n",
    "The program may be ammended to create any number of word clouds given an input txt file. A csv file may be used as well, the relavent information from which is parsed and saved into a txt file for use by the word cloud function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Author: Elizabeth Brooks\n",
    "# Date Modified: 06/25/2015\n",
    "# Edited: Hayden Fuss\n",
    "\n",
    "# PreProcessor Directives\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "# Make sure to use < pip install pillow >\n",
    "# With anaconda, use < conda install pil >\n",
    "from wordcloud import WordCloud\n",
    "from scipy.misc import imread\n",
    "import re\n",
    "# Add parent directory to path for twc imports\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.realpath('../'))\n",
    "import twittercriteria as twc\n",
    "\n",
    "# Global field declarations\n",
    "twc.loadCriteria()\n",
    "keyword = twc.getKeywordRegex()\n",
    "twc.clearCriteria()\n",
    "\n",
    "# Function to clean up tweet strings \n",
    "# by manually removing irrelevant data (not words)\n",
    "def cleanUpTweet(tweet):\n",
    "    # Irrelevant characters\n",
    "    twitter_markup = ['&amp;', 'http://t.co/']\n",
    "    temp = tweet.lower()\n",
    "    # Use regex to create a regular expression \n",
    "    # for removing undesired characters\n",
    "    temp = re.sub('|'.join(twitter_markup), r\"\", temp)\n",
    "    return temp\n",
    "# End cleanUpTweet\n",
    "## The markup and the cleanUpTweet function will eventually \n",
    "## be moved to twc\n",
    "\n",
    "# Function to search for tweets wased on pre-determined key words\n",
    "def tweetHasAKeyword(tweet):\n",
    "    return keyword.search(tweet) is not None\n",
    "# End tweetHasAKeyword\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function .cleanUpTweet(String) is used to remove irrelevant data, characters that are not words and are therefore not interesting. In order to produce a more refined word cloud, the .tweetHasAKeyword(String) searches the data set of cleaned tweet strings for those tweets containing our pre-determined set of key words (see below).\n",
    "\n",
    "keywords: [\"#bostonmarathon\",\n",
    "           \"#marathonmonday\",\n",
    "           \"#patriotsday\",\n",
    "           \"marathon\",\n",
    "           \"boylston\",\n",
    "           \"finish line\",\n",
    "           \"#bostonstrong\",\n",
    "           \"#bostonpride\",\n",
    "           \"#prayforboston\",\n",
    "           \"#pray4bos\",\n",
    "           \"bomb\",\n",
    "           \"explosion\",\n",
    "           \"explode\",\n",
    "           \"wounded\",\n",
    "           \"hostage\",\n",
    "           \"watertown\",\n",
    "           \"lockdown\",\n",
    "           \"manhunt\",\n",
    "           \"collier\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Function for generating a word cloud\n",
    "## Windows OS specific font path in arguments\n",
    "### On Windows, if the given file name does not exist, \n",
    "### the loader also looks in Windows fonts directory\n",
    "def tweetWordCloud(filepath, maskpath=None, bg_color='white', num_words=150,\n",
    "                   fontpath='sans-serif.ttf', outpath='keywordCloud.png'):\n",
    "    # Read in the txt file set by the main method\n",
    "    text = open(filepath, 'r').read()\n",
    "    # Generate the word cloud based on the input arguments\n",
    "    wc = None\n",
    "    if maskpath:\n",
    "        # Use module to read the image file\n",
    "        mass_mask = imread(maskpath)\n",
    "        wc = WordCloud(mask=mass_mask, background_color=bg_color, max_words=num_words, \n",
    "                       font_path=fontpath).generate(text)\n",
    "    else:\n",
    "        wc = WordCloud(font_path=fontpath, max_words=num_words,\n",
    "                       background_color=bg_color).generate(text)\n",
    "    # Open a plot of the generated word cloud\n",
    "    wc.to_file(outpath)\n",
    "    plt.imshow(wc)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "# End tweetWordCloud\n",
    "## We can eventually move this to its own module\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above function generates a word cloud based on words in the txt file created in the main method.\n",
    "For more info see: https://github.com/amueller/word_cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "cannot open resource",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-902a2c385932>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# Run the script via the main method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;31m# End script\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-902a2c385932>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m# Use the defined function to create the tweet word cloud\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;31m# in the shape of Massachusets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mtweetWordCloud\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/mass_map.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;31m# End main\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-df1d55c87d81>\u001b[0m in \u001b[0;36mtweetWordCloud\u001b[0;34m(filepath, maskpath, bg_color, num_words, fontpath, outpath)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mmass_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaskpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         wc = WordCloud(mask=mass_mask, background_color=bg_color, max_words=num_words, \n\u001b[0;32m---> 15\u001b[0;31m                        font_path=fontpath).generate(text)\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         wc = WordCloud(font_path=fontpath, max_words=num_words,\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/wordcloud/wordcloud.pyc\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    396\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m         \"\"\"\n\u001b[0;32m--> 398\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_from_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check_generated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/wordcloud/wordcloud.pyc\u001b[0m in \u001b[0;36mgenerate_from_text\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    382\u001b[0m         \"\"\"\n\u001b[1;32m    383\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/wordcloud/wordcloud.pyc\u001b[0m in \u001b[0;36mfit_words\u001b[0;34m(self, frequencies)\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         \"\"\"\n\u001b[0;32m--> 203\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_from_frequencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrequencies\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgenerate_from_frequencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrequencies\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/wordcloud/wordcloud.pyc\u001b[0m in \u001b[0;36mgenerate_from_frequencies\u001b[0;34m(self, frequencies)\u001b[0m\n\u001b[1;32m    259\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m                 \u001b[0;31m# try to find a position\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 261\u001b[0;31m                 \u001b[0mfont\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImageFont\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtruetype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfont_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfont_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    262\u001b[0m                 \u001b[0;31m# transpose font optionally\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprefer_horizontal\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/PIL/ImageFont.pyc\u001b[0m in \u001b[0;36mtruetype\u001b[0;34m(filename, size, index, encoding)\u001b[0m\n\u001b[1;32m    216\u001b[0m     \u001b[0;34m\"Load a truetype font file.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mFreeTypeFont\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplatform\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"win32\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/PIL/ImageFont.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, size, index, encoding)\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;31m# FIXME: use service provider instead\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfont\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetfont\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgetname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: cannot open resource"
     ]
    }
   ],
   "source": [
    "# The main method\n",
    "def main():\n",
    "    # Set the output image file path\n",
    "    current_dir = os.getcwd()\n",
    "    filepath = current_dir + '/OutputTweets.txt'    # Create object for writting to a text file\n",
    "    tweetFile = open(filepath, \"w\")\n",
    "    # Iterate through the \"cleaned\" Twitter data by tweet\n",
    "    with open(current_dir + '/../cleaned_geo_tweets_Apr_12_to_22.csv') as csvfile:  \n",
    "        tweetIt = csv.DictReader(csvfile)\n",
    "        # Retrieve the strings of tweets\n",
    "        for twitterData in tweetIt:\n",
    "            # Convert tweets to lower case to pool words of the same spelling\n",
    "            tweet_text = cleanUpTweet(twitterData['tweet_text'])\n",
    "            # Write the selected Twitter data, tweets, to the txt file\n",
    "            if tweetHasAKeyword(tweet_text):\n",
    "                tweetFile.write(tweet_text)\n",
    "    # Close the file obj\n",
    "    tweetFile.close()  \n",
    "    # Use the defined function to create the tweet word cloud\n",
    "    # in the shape of Massachusets\n",
    "    tweetWordCloud(filepath, current_dir + '/mass_map.png')\n",
    "# End main\n",
    "\n",
    "# Run the script via the main method\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "    \n",
    "# End script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code creates a file object and opens a txt file to store all the strings of tweets contained in the Twitter data from the \"cleaned\" tweets csv file. The tweet strings are then retrieved from the csv file by iterating through the tweet hashes made by the DictReader. Finally, these strings are converted to lower case. This is because we are interested in looking at the occurances of a given spelling of a word, regardless of case; stemming may be considered in the future to combine the frequencies of all conjugate forms of a words."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
